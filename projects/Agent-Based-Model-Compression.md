# Agent-Based Model Compression

## 프로젝트 개요

강화학습을 활용하여 대규모 언어 모델을 자동으로 압축하는 연구 프로젝트입니다. 성능 손실을 최소화하면서 모델 크기를 줄여 온디바이스 AI 배포를 가능하게 하는 것이 목표입니다.

## 주요 기능

- 강화학습 기반 자동 압축 전략 학습
- Pruning, Quantization, Distillation 기법 통합 적용
- 실시간 성능 모니터링 및 최적화
- 다양한 모델 아키텍처 지원

## 기술 스택

**Framework**: PyTorch, Transformers
**RL**: Custom RL Environment
**Deployment**: Docker, CUDA
**Monitoring**: Weights & Biases

## 구현 과정

### 1. 강화학습 환경 설계
모델 압축을 위한 MDP(Markov Decision Process)를 정의했습니다. 상태는 현재 모델 구조와 성능 지표이고, 행동은 압축 기법과 파라미터 선택입니다.

### 2. 압축 기법 통합
- **Pruning**: 중요도가 낮은 가중치 제거
- **Quantization**: 가중치 정밀도 축소
- **Knowledge Distillation**: 큰 모델의 지식을 작은 모델로 전이

### 3. 보상 함수 설계
성능 유지율, 압축률, 추론 속도를 고려한 다목적 최적화 보상 함수를 구현했습니다.

## 실험 결과

BERT-Base 모델 기준:
- 모델 크기 78% 감소
- 추론 속도 4.1배 향상
- 성능 유지율 96%

## 성과 및 한계

**성과**:
- 수동 압축 대비 우수한 성능-효율성 트레이드오프
- 다양한 모델에서 일관된 압축 성과
- 자동화된 최적화 프로세스

**한계**:
- 학습 시간이 오래 걸림
- 특정 도메인에서의 성능 검증 부족

## 개선 방향

- 메타 러닝을 통한 빠른 적응
- 하드웨어별 최적화 고려
- 더 다양한 압축 기법 통합

---

[메인으로 돌아가기](../README.md)